import streamlit as st
import pandas as pd
from rank_bm25 import BM25Okapi
from langchain import LLMChain
from langchain.prompts import PromptTemplate
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.chains import LLMChain
from langchain.schema import HumanMessage
import os

# OpenAI API í‚¤ ì„¤ì •
os.environ["API_KEY"] = "" 

# ëª¨ë¸ ë° ë°ì´í„° ì´ˆê¸°í™” í•¨ìˆ˜
@st.cache_resource
def initialize_models():
    # CSV ë°ì´í„° ë¡œë“œ
    file_path = './data/ì‘ê¸‰ì²˜ì¹˜_ì¦ìƒ_data_final.csv'
    df = pd.read_csv(file_path)
    df['ì‹¬ê°ë„2'] = df['ì‹¬ê°ë„2'].fillna('ì—†ìŒ')  # NaN ì²˜ë¦¬
    
    # ë³‘ì› ë°ì´í„° ë¡œë“œ
    hospital_file_path = r'C:\Users\user\langchain\study_langchain\emergency_streamlit\data\emergency_hospital_data_final.csv'  # ë³‘ì› ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì˜ˆì‹œ
    hospital_df = pd.read_csv(hospital_file_path)
    
    # BM25 ì´ˆê¸°í™”
    tokenized_corpus = [symptom.split() for symptom in df['ì¦ìƒ']]
    bm25 = BM25Okapi(tokenized_corpus)

    # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
    embeddings = OpenAIEmbeddings()
    index = FAISS.load_local('./data/symptom_index/', embeddings, allow_dangerous_deserialization=True)

    return df, bm25, embeddings, index, hospital_df  # ë³‘ì› ë°ì´í„°ë„ í•¨ê»˜ ë°˜í™˜

# ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def generate_response(symptom_input, df, bm25, embeddings, index, hospital_df):
    if not symptom_input.strip():
        return "ì¦ìƒì„ ì…ë ¥í•´ì£¼ì„¸ìš”."

    # BM25 ê¸°ë°˜ ê²€ìƒ‰
    symptom_tokens = symptom_input.split()
    scores = bm25.get_scores(symptom_tokens)
    top_indices_bm25 = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:5]
    matched_bm25_index = [i for i in top_indices_bm25 if scores[i] > 0]
    bm25_row = df.iloc[matched_bm25_index[0]] if matched_bm25_index else None

    # FAISS ê¸°ë°˜ ê²€ìƒ‰
    query_embedding = embeddings.embed_query(symptom_input.lower().strip())
    search_results = index.similarity_search_by_vector(query_embedding, k=5)

    matched_llm_row = None
    highest_similarity_score = -1
    for result in search_results:
        matched_text = result.page_content
        symptom_in_data = matched_text.split("\n")[0].replace("ì¦ìƒ: ", "").lower().strip()
        similarity_score = result.score if hasattr(result, 'score') else 0

        if similarity_score > highest_similarity_score:
            highest_similarity_score = similarity_score
            matched_llm_row = df[df['ì¦ìƒ'].str.lower().str.strip() == symptom_in_data].iloc[0]

    # BM25ì™€ FAISS ê²°í•© ê²°ê³¼ ì„ íƒ
    best_row = bm25_row if bm25_row is not None else matched_llm_row

    if best_row is not None:
        symptom = best_row['ì¦ìƒ']
        emergency_action = best_row['ì‘ê¸‰ì²˜ì¹˜']
        severity1 = best_row['ì‹¬ê°ë„1']
        severity2 = best_row['ì‹¬ê°ë„2']
        related_field = best_row['ì§„ë£Œê³¼ëª©']  # ì§„ë£Œê³¼ëª©ì„ ê°€ì ¸ì˜´

        # ì‘ê¸‰ì²˜ì¹˜ ë° ë³‘ì› ì¶”ì²œ ì•ˆë‚´
        if severity1 == 'ì¤‘ì¦' and severity2 == 'ì—†ìŒ':
            return (
                f"ì¡°ê¸‰í•œ ë§ˆìŒì€ ì‹¤ìˆ˜ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìœ¼ë‹ˆ ì ‘ì–´ë‘ê³ .\n\n"
                f"ì²œì²œíˆ ì´ ë‹¤ìŒì„ ë”°ë¼ì™€ì£¼ì„¸ìš” \n{emergency_action}\n\n"
                f"ì´ ì§„ë£Œ ê´€ë ¨ ì‘ê¸‰ì‹¤ì„ ë¹ ë¥´ê²Œ ì•Œë ¤ë“œë¦´ê²Œìš”! í˜„ì¬ ìœ„ì¹˜ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.", related_field
            )
        elif severity1 == 'ê²½ì¦' and severity2 == 'ì—†ìŒ':
            return (
                f"íœ´ ë‹¤í–‰ì´ë„ ìœ„í—˜í•œ ì¦ìƒì€ ì•„ë‹ˆë„¤ìš”.\n\n"
                f"ì œê°€ ì´ì œ ì‘ê¸‰ì²˜ì¹˜ë¥¼ ë„ì™€ë“œë¦´ê²Œìš”. \n{emergency_action}\n\n"
                f"ì¦ìƒì´ ì•…í™”ë˜ê±°ë‚˜ ì¤‘ì¦ ì¦ìƒì´ ë‚˜íƒ€ë‚˜ë©´ ì¦‰ì‹œ ì‘ê¸‰ì‹¤ì„ ë°©ë¬¸í•˜ì„¸ìš”. "
                f"ì°¸ê³ ë¡œ, ì‘ê¸‰ì‹¤ ë°©ë¬¸ ì‹œ ê²½ì¦ìœ¼ë¡œ ë¶„ë¥˜ë˜ë©´ ì˜ë£Œë¹„ ë¶€ë‹´ì´ ë†’ì•„ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
                f"ì¶”ê°€ì ì¸ ì§ˆë¬¸ì´ë‚˜ ë³´ìƒ ê´€ë ¨ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”!", related_field
            )
        elif severity1 == 'ê²½ì¦' and severity2 == 'ì¤‘ì¦':
            return (
                f"ì‘ê¸‰ì‹¤ê°€ì‹œê¸° ì „ ìš°ì„  ê¸‰í•œëŒ€ë¡œ ë‹¤ìŒì„ ë”°ë¼ì™€ì£¼ì„¸ìš”. ë¹ ë¥¸ í˜¸ì „ì´ ê°€ëŠ¥í•  ìˆ˜ ìˆì–´ìš”.\n\n"
                f"ìš°ì„  \n{emergency_action}\n\n ê·¸ë˜ë„ ì•ˆë˜ë©´ ì‘ê¸‰ì‹¤ì„ ìƒê°í•´ ë³¼ ìˆ˜ë„ ìˆì„ ê²ƒ ê°™ì•„ìš”."
                f"ì¦ìƒì´ ìƒê°ë³´ë‹¤ ì‹¬í•˜ê³  ì¶”ê°€ ì¦ìƒì´ ìˆìœ¼ë©´ ì•Œë ¤ì£¼ì„¸ìš”. "
                f"ê´œì°®ì•„ì§€ì‹¤ ê±°ì˜ˆìš”! ì¶”ê°€ì ìœ¼ë¡œ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë‹¤ì‹œ ë¬¸ì˜í•´ì£¼ì„¸ìš”!", related_field
            )
    else:
        return "í˜„ì¬ ì…ë ¥ëœ ì¦ìƒì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì¦ìƒì„ ë§ì”€í•´ì£¼ì‹œë©´ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”.", None

# OpenAI ëª¨ë¸ ì´ˆê¸°í™”
model = ChatOpenAI(model='gpt-4')

# LangChain Prompt Template ì •ì˜
prompt_template = PromptTemplate(
    input_variables=["medical_field", "district", "recommendations"],
    template=(
        "ì‚¬ìš©ìê°€ '{medical_field}' ì§„ë£Œê³¼ëª©ìœ¼ë¡œ '{district}' êµ¬ì—­ì˜ ì‘ê¸‰ì‹¤ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤. "
        "ë‹¤ìŒì€ ì¶”ì²œë˜ëŠ” ë³‘ì› ëª©ë¡ì…ë‹ˆë‹¤:\n\n{recommendations}\n\n"
        "ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì‘ê¸‰ì‹¤ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”."
    ),
)

# ì‘ê¸‰ì‹¤ ì¶”ì²œ ì •ë³´ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
def generate_emergency_response(medical_field_input, user_district, df, hospital_df):
    # ì¶”ì²œ ë³‘ì› ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    recommendations = recommend_emergency_room(df, medical_field_input, user_district, hospital_df)
    
    # LangChainì„ í†µí•œ ì‘ë‹µ ìƒì„±
    chain = LLMChain(llm=model, prompt=prompt_template)
    
    # HumanMessageë¥¼ í†µí•´ ëª¨ë¸ì—ê²Œ ì •í™•í•œ ìš”ì²­ ì „ë‹¬
    human_message = HumanMessage(content=recommendations)
    
    # ì‘ë‹µ ìƒì„±
    response = chain.run({
        "medical_field": medical_field_input,
        "district": user_district,
        "recommendations": human_message.content  # ì‘ê¸‰ì‹¤ ì¶”ì²œ ì •ë³´ë¥¼ í¬í•¨ì‹œí‚´
    })
    
    return response

# ì‘ê¸‰ì‹¤ ì•ˆë‚´ ëª¨ë¸ ìˆ˜ì •
def recommend_emergency_room(df, medical_field_input, user_district, hospital_df):
    """
    ì§„ë£Œê³¼ëª©ê³¼ ì‚¬ìš©ì ì§€ì—­ì„ ê¸°ë°˜ìœ¼ë¡œ ë³‘ì› ì •ë³´ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.
    """
    relevant_hospitals = hospital_df[ 
        hospital_df.loc[:, 'ì§„ë£Œê³¼ëª©1':'ì§„ë£Œê³¼ëª©36']
        .apply(lambda row: row.str.contains(medical_field_input, case=False, na=False).any(), axis=1)
    ]
    relevant_hospitals = relevant_hospitals[
        relevant_hospitals['êµ¬ì—­'].str.contains(user_district, case=False, na=False)
    ]

    if not relevant_hospitals.empty:
        recommendations = [
            f"{row['ë³‘ì›']}, ì£¼ì†Œ: {row['ì£¼ì†Œ']}, ì „í™”ë²ˆí˜¸: {row['ì „í™”ë²ˆí˜¸']}"
            for _, row in relevant_hospitals.iterrows()
        ]
        return "\n".join(recommendations)
    else:
        return "í•´ë‹¹ ì§„ë£Œê³¼ëª© ë° ì§€ì—­ì— ë§ëŠ” ì‘ê¸‰ì‹¤ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."

def display_chatbot_page():
    # ëª¨ë¸ ì´ˆê¸°í™”
    df, bm25, embeddings, index, hospital_df = initialize_models()  # ëª¨ë“  ë°˜í™˜ê°’ì„ ë°›ì•„ì•¼ í•¨

    st.title("ğŸ¤– ìŠ¤ë§ˆíŠ¸ ì‘ê¸‰ì²˜ì¹˜ ì±—ë´‡")
    st.write("ì‘ê¸‰ì²˜ì¹˜ ì •ë³´ë¥¼ ì–»ê³  ì‹¶ì€ ì¦ìƒì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    symptom_input = st.text_input("ğŸ’¬ ì¦ìƒì„ ì…ë ¥í•˜ì„¸ìš”:", "")
    
    if symptom_input:
        response, related_field = generate_response(symptom_input, df, bm25, embeddings, index, hospital_df)  # ëª¨ë“  ëª¨ë¸ì„ ì—°ê²°
        
        st.write(response)

        # ì‘ê¸‰ì‹¤ ì•ˆë‚´ê°€ í•„ìš”í•œ ê²½ìš° ì§€ì—­ ì…ë ¥ ë°›ê¸°
        if related_field:  # ì§„ë£Œê³¼ëª©ì´ ìˆì„ ê²½ìš°ì—ë§Œ ì‘ê¸‰ì‹¤ ì•ˆë‚´
            st.write("ğŸ“ êµ¬ì—­ì„ ì…ë ¥í•˜ì„¸ìš”. ì˜ˆì‹œ: ê°•ì„œêµ¬, êµ¬ë¡œêµ¬")

            user_district = st.text_input("êµ¬ì—­ì„ ì…ë ¥í•˜ì„¸ìš”:", "")
            if user_district:  # êµ¬ì—­ì´ ì…ë ¥ë˜ì—ˆì„ ë•Œ
                emergency_room_response = generate_emergency_response(related_field, user_district, df, hospital_df)
                st.write(emergency_room_response)

# ì±—ë´‡ í˜ì´ì§€ ì‹¤í–‰
display_chatbot_page()









