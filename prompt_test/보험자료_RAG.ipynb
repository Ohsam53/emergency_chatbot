{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 보험사 RAG 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "1113\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "loader = PyMuPDFLoader('./data/약관_31043(01)_나에게맞춘생활종합보험2404_20241001.pdf')\n",
    "docs = loader.load()\n",
    "\n",
    "print(type(docs))\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000, # 내가 몇개의 문자 단위로 나눌 건지 (토큰 아님)\n",
    "    chunk_overlap = 200 # 겹친 글자 수 정해줌 (context 애매하게 짤리지 않게)\n",
    "    ) \n",
    "\n",
    "split_docs = splitter.split_documents(docs)\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "embedded_docs = embedding.embed_documents([content.page_content for content in split_docs])\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=split_docs,\n",
    "    embedding=embedding\n",
    ")\n",
    "\n",
    "# 검색기 생성\n",
    "retriever = vectorstore.as_retriever()\n",
    "retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "관련 내용:\n",
      "있습니다.  ①  아나필락시스쇼크진단비(최초1회한) ②  아나필락시스쇼크진단비(연간1회한)  󰊲 회사는  보험증권에  기재된  피보험자가  이  특별약관의  보험기간  중에  “아나필락시스 쇼크”로  진단  확정된  경우에는  아나필락시스쇼크진단비를  다음과  같이  지급합니다.  구분  아나필락시스 쇼크진단비  아나필락시스쇼크진단비 (최초1회한)  아나필락시스쇼크진단비 (연간1회한)  보험가입금액의  90%  보험가입금액의  10%  󰊳 위  󰊲의  “연간”이란,  보험기간  시작일부터  그날을  포함하여  매1년  단위로  도래하 는  계약해당일(최초  보험기간  시작일과  동일한  월,일을  말합니다)  전일까지의  기 간을  말합니다.  ⑥  간호ㆍ간병통합서비스  제공기관은  간호ㆍ간병통합서비스  제공인력의  근무  환경  및  처우  개선을  위하여  필요한  지원을  하여야  한다.  ⑦  국가  및  지방자치단체는  간호ㆍ간병통합서비스의  제공ㆍ확대,  간호ㆍ간병 통합서...\n",
      "--------------------------------------------------\n",
      "관련 내용:\n",
      "130  \f아나필락시스쇼크진단비  보장예시  (가입금액  100만원  기준)  용어 풀이  2022.1.1 계약체결일자            2024.3.1     (첫  번째  진단일)      2026.1.1       (진단일)  2032.1.1 (갱신일자)  2032.5.1 (진단일)  세부보장  아나필락시스 쇼크진단비 (최초1회한)  90만원 지급  아나필락시스 쇼크진단비 (연간1회한)  10만원 지급  최초  1회  지급  후  소멸  10만원  지급  10만원 지급  연간  1회  한도로  계속  보장  아나필락시스 쇼크진단비  총100만원 지급  총10만원 지급  총10만원 지급  2.  (보험금  지급에  관한  세부규정) 󰊱 3.(“아나필락시스쇼크”의  정의  및  진단확정)의  “아나필락시스쇼크”의  진단은  임상적  특징  또는  혈액,  항원검사,  유발검사  및  피부시험  등을  기초로  내려져야합니다. 󰊲 피보험자가  사망하여  그  후  아나필락시스쇼크를...\n",
      "--------------------------------------------------\n",
      "관련 내용:\n",
      "구분  담보명  면책기간  암진단특약  암  진단비  가입  후  90일간  보장  제외  치매진단특약  경증이상  치매  진단비  가입  후  1년간  보장  제외  사례  A씨는  암보험  가입  후  2개월이  지나서  위암을  판정받아  보험회사에  암진단비를  청구 ▶  회사는  보험가입  후  90일이  경과하지  않아  보험금  지급이  어려움  을  안내  ▪감액지급  감액지급  50% [1년  이내]  ▪보장한도  보장한도  최초 1회한  보장한도  보험금  지급한도  적용  16  일정기간  보험금이  일부만  지급(감액지급)되는  담보가  있을  수  있습 니다.  [감액지급  적용  담보  예시]  구분  담보명  감액  기간  및  비율  급성심근경색 진단특약  급성심근경색 증  진단비  가입  후  1년간  보험금  50%  지급  보험금  지급  한도가  설정된  담보가  있을  수  있습니다.  [보장한도  적용  담보  예시]  구분  담보명  보장한도...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "\n",
    "# 1. pdfminer로 텍스트 추출\n",
    "pdf_file_path = './data/약관_31043(01)_나에게맞춘생활종합보험2404_20241001.pdf'\n",
    "text = extract_text(pdf_file_path)\n",
    "\n",
    "# 2. 텍스트를 페이지별로 나누는 방법\n",
    "# 예시에서는 페이지 구분이 없으므로 간단히 한 덩어리로 텍스트를 추출\n",
    "# 만약 페이지 구분이 필요하다면, PDF에서 페이지마다 텍스트를 추출해 저장할 수 있습니다.\n",
    "\n",
    "# 3. 문서 분할 (청크화)\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,  # 청크 크기 설정\n",
    "    chunk_overlap=100  # 약간의 오버랩을 두어 문맥 유지\n",
    ")\n",
    "\n",
    "# 텍스트를 청크화\n",
    "split_docs = []\n",
    "chunks = splitter.split_text(text)\n",
    "\n",
    "# 청크화된 텍스트를 Document 객체로 변환\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk_metadata = {\n",
    "        \"source\": \"약관\",  # 소스는 '약관'으로 설정 (필요시 변경)\n",
    "        \"page\": i + 1  # 페이지 정보 (이 경우 인덱스를 사용)\n",
    "    }\n",
    "    document = Document(page_content=chunk, metadata=chunk_metadata)\n",
    "    split_docs.append(document)\n",
    "\n",
    "# 4. 임베딩 생성\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# 5. 벡터 스토어 생성\n",
    "faiss_db = FAISS.from_documents(split_docs, embedding)\n",
    "\n",
    "# 6. 검색기 생성 (튜닝 포함)\n",
    "retriever = faiss_db.as_retriever(search_kwargs={\"k\": 3})  # 관련 결과 3개만 반환\n",
    "\n",
    "# 7. 증상 기반 검색 함수 정의\n",
    "def search_insurance_terms(symptom):\n",
    "    \"\"\"\n",
    "    주어진 증상(symptom)과 관련된 보험 약관을 검색.\n",
    "    \"\"\"\n",
    "    results = retriever.get_relevant_documents(symptom)  # 증상 기반 검색\n",
    "    for result in results:\n",
    "        # 의미 있는 청크들만 출력\n",
    "        if len(result.page_content) > 50 and \"보험\" in result.page_content:\n",
    "            # 결과를 문장 단위로 출력 (적절한 길이로 자르기)\n",
    "            summary = result.page_content[:500]  # 500자까지 출력\n",
    "            summary = summary.replace('\\n', ' ')  # 줄바꿈 제거\n",
    "            print(f\"관련 내용:\\n{summary}...\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "# 8. 테스트: 증상 검색\n",
    "symptom_query = \"아나팔락시스 보험\"  # 간단하게 주요 키워드만 사용\n",
    "search_insurance_terms(symptom_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "관련 내용:\n",
      "있습니다.  ①  아나필락시스쇼크진단비(최초1회한) ②  아나필락시스쇼크진단비(연간1회한)  󰊲 회사는  보험증권에  기재된  피보험자가  이  특별약관의  보험기간  중에  “아나필락시스 쇼크”로  진단  확정된  경우에는  아나필락시스쇼크진단비를  다음과  같이  지급합니다.  구분  아나필락시스 쇼크진단비  아나필락시스쇼크진단비 (최초1회한)  아나필락시스쇼크진단비 (연간1회한)  보험가입금액의  90%  보험가입금액의  10%  󰊳 위  󰊲의  “연간”이란,  보험기간  시작일부터  그날을  포함하여  매1년  단위로  도래하 는  계약해당일(최초  보험기간  시작일과  동일한  월,일을  말합니다)  전일까지의  기 간을  말합니다.  ⑥  간호ㆍ간병통합서비스  제공기관은  간호ㆍ간병통합서비스  제공인력의  근무  환경  및  처우  개선을  위하여  필요한  지원을  하여야  한다.  ⑦  국가  및  지방자치단체는  간호ㆍ간병통합서비스의  제공ㆍ확대,  간호ㆍ간병 통합서...\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "\n",
    "# 1. PDF에서 텍스트 추출\n",
    "pdf_file_path = './data/약관_31043(01)_나에게맞춘생활종합보험2404_20241001.pdf'\n",
    "text = extract_text(pdf_file_path)\n",
    "\n",
    "# 2. 텍스트를 페이지별로 나누는 방법\n",
    "# 페이지 구분이 필요하다면 페이지마다 텍스트를 추출하여 분리 가능\n",
    "# (예시에서는 페이지 구분 없이 한 덩어리로 처리)\n",
    "\n",
    "# 3. 텍스트를 청크화 (문서 분할)\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,  # 청크 크기 설정\n",
    "    chunk_overlap=100  # 약간의 오버랩을 두어 문맥 유지\n",
    ")\n",
    "\n",
    "# 텍스트를 청크화하여 문서 목록 생성\n",
    "split_docs = []\n",
    "chunks = splitter.split_text(text)\n",
    "\n",
    "# 청크화된 텍스트를 Document 객체로 변환\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk_metadata = {\n",
    "        \"source\": \"약관\",  # 소스 정보 설정\n",
    "        \"page\": i + 1  # 페이지 정보 설정\n",
    "    }\n",
    "    document = Document(page_content=chunk, metadata=chunk_metadata)\n",
    "    split_docs.append(document)\n",
    "\n",
    "# 4. 임베딩 생성\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# 5. 벡터 스토어 생성\n",
    "faiss_db = FAISS.from_documents(split_docs, embedding)\n",
    "\n",
    "# 6. 검색기 생성 (튜닝 포함)\n",
    "retriever = faiss_db.as_retriever(search_kwargs={\"k\": 3})  # 관련 결과 3개만 반환\n",
    "\n",
    "# 7. 증상 기반 검색 함수 정의\n",
    "def search_insurance_terms(symptom):\n",
    "    \"\"\"\n",
    "    주어진 증상(symptom)과 관련된 보험 약관을 검색하고,\n",
    "    가장 관련성 높은 문서 하나만 추출하는 함수.\n",
    "    \"\"\"\n",
    "    results = retriever.get_relevant_documents(symptom)  # 증상 기반 검색\n",
    "    if results:\n",
    "        # 첫 번째 결과는 가장 유사도가 높은 문서\n",
    "        best_result = results[0]\n",
    "        \n",
    "        # 결과 출력\n",
    "        summary = best_result.page_content[:500]  # 500자까지 출력\n",
    "        summary = summary.replace('\\n', ' ')  # 줄바꿈 제거\n",
    "        print(f\"관련 내용:\\n{summary}...\")\n",
    "    else:\n",
    "        print(\"관련된 내용이 없습니다.\")\n",
    "\n",
    "# 8. 테스트: 증상 검색\n",
    "symptom_query = \"아나팔락시스 보험\"  # 간단한 주요 키워드로 검색\n",
    "search_insurance_terms(symptom_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "관련 내용:\n",
      "5.  (준용규정) 이  특별약관에  정하지  않은  사항은  보통약관을  따릅니다.  단,  이  특별약관에서는  보 통약관에서  정한  9.(만기환급금의  지급)의  만기환급금  및  37.(중도인출금)의  중도인출 금은  지급하지  않습니다.  27 독액성동물접촉중독진단비(연간1회한)  특별약관  1.  (보험금의  지급사유) 󰊱 회사는  보험증권에  기재된  피보험자가  「이  특별약관의  보험기간」  중에  「독액성  동 물과의  접촉으로  인한  중독」으로  진단  확정된  경우에는  연간  1회에  한하여  이  특 별약관의  보험가입금액을  독액성동물접촉중독진단비로  보험수익자에게  지급합니다. 󰊲 위  󰊱의  독액성동물접촉중독진단비는  “독액성  동물과의  접촉으로  인한  중독”의  직 접적인  원인,  중독의  종류  및  중독  부위와  상관없이  연간  1회를  초과하여  지급하 지  않습니다.  󰊳 위  󰊱의  “연간”이란,  보험기간  시작일부터  그날을 ...\n"
     ]
    }
   ],
   "source": [
    "symptom_query = \"독성 동물 접촉 보험\"  # 간단하게 주요 키워드만 사용\n",
    "search_insurance_terms(symptom_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  챗봇 답변 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_17788\\1788019336.py:75: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)  # Use ChatOpenAI instead of OpenAI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변: 아나필락시스 보험에 대한 내용을 알려드릴게요. 아나필락시스 보험은 아나필락시스 쇼크 진단비를 지급하는 것으로 보입니다. 이 보험은 아나필락시스 쇼크로 진단 확정된 경우에 해당하며, 보험가입금액의 일부를 지급해줍니다. 연간 1회까지 지원되는데, 연간이란 보험기간 시작일부터 매년 계약해당일 전일까지를 의미합니다. 또한, 간호ㆍ간병통합서비스 제공기관은 제공인력의 근무 환경 및 처우 개선을 위해 지원을 하여야 한다고 합니다. 국가 및 지방자치단체도 간호ㆍ간병통합서비스의 제공 및 확대에 관심을 가지고 있습니다. 이렇게요. 더 궁금한 점 있으시면 언제든지 물어봐주세요.\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI  # Import the correct model\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# 1. PDF에서 텍스트 추출\n",
    "pdf_file_path = './data/약관_31043(01)_나에게맞춘생활종합보험2404_20241001.pdf'\n",
    "text = extract_text(pdf_file_path)\n",
    "\n",
    "# 2. 텍스트를 페이지별로 나누는 방법\n",
    "# 페이지 구분이 필요하다면 페이지마다 텍스트를 추출하여 분리 가능\n",
    "# (예시에서는 페이지 구분 없이 한 덩어리로 처리)\n",
    "\n",
    "# 3. 텍스트를 청크화 (문서 분할)\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,  # 청크 크기 설정\n",
    "    chunk_overlap=100  # 약간의 오버랩을 두어 문맥 유지\n",
    ")\n",
    "\n",
    "# 텍스트를 청크화하여 문서 목록 생성\n",
    "split_docs = []\n",
    "chunks = splitter.split_text(text)\n",
    "\n",
    "# 청크화된 텍스트를 Document 객체로 변환\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk_metadata = {\n",
    "        \"source\": \"약관\",  # 소스 정보 설정\n",
    "        \"page\": i + 1  # 페이지 정보 설정\n",
    "    }\n",
    "    document = Document(page_content=chunk, metadata=chunk_metadata)\n",
    "    split_docs.append(document)\n",
    "\n",
    "# 4. 임베딩 생성\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# 5. 벡터 스토어 생성\n",
    "faiss_db = FAISS.from_documents(split_docs, embedding)\n",
    "\n",
    "# 6. 검색기 생성 (튜닝 포함)\n",
    "retriever = faiss_db.as_retriever(search_kwargs={\"k\": 3})  # 관련 결과 3개만 반환\n",
    "\n",
    "# 7. 증상 기반 검색 함수 정의 (자연스러운 답변 생성 추가)\n",
    "def search_insurance_terms(symptom):\n",
    "    \"\"\"\n",
    "    주어진 증상(symptom)과 관련된 보험 약관을 검색하고,\n",
    "    가장 관련성 높은 문서를 추출한 뒤, 챗봇 스타일의 응답을 생성하는 함수.\n",
    "    \"\"\"\n",
    "    results = retriever.get_relevant_documents(symptom)  # 증상 기반 검색\n",
    "    if results:\n",
    "        # 첫 번째 결과는 가장 유사도가 높은 문서\n",
    "        best_result = results[0]\n",
    "        \n",
    "        # 결과 요약\n",
    "        summary = best_result.page_content[:500]  # 500자까지 출력\n",
    "        summary = summary.replace('\\n', ' ')  # 줄바꿈 제거\n",
    "\n",
    "        # 챗봇 응답을 위한 자연스러운 대화 생성\n",
    "        # OpenAI GPT 모델을 사용하여 응답 생성\n",
    "        prompt_template = \"\"\"\n",
    "        주어진 보험 약관에 대한 정보를 바탕으로 아래와 같이 질문에 대해 답변을 해주세요:\n",
    "        \n",
    "        사용자가 궁금해하는 주제: {symptom}\n",
    "        관련 내용: {summary}\n",
    "        \n",
    "        질문에 대한 자연스럽고 대화식으로 답변을 생성해주세요.\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt = PromptTemplate(input_variables=[\"symptom\", \"summary\"], template=prompt_template)\n",
    "        \n",
    "        # Change OpenAI to ChatOpenAI\n",
    "        llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)  # Use ChatOpenAI instead of OpenAI\n",
    "        chain = LLMChain(llm=llm, prompt=prompt)\n",
    "        \n",
    "        # 자연스러운 대화식 답변 생성\n",
    "        response = chain.run({\"symptom\": symptom, \"summary\": summary})\n",
    "\n",
    "        print(f\"답변: {response}\")\n",
    "    else:\n",
    "        print(\"관련된 내용이 없습니다.\")\n",
    "\n",
    "# 8. 테스트: 증상 검색\n",
    "symptom_query = \"아나팔락시스 보험\"  # 간단한 주요 키워드로 검색\n",
    "search_insurance_terms(symptom_query)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변: 골절 관련된 보험에 대해 알려드릴게요. 약관 요약서에 따르면, 보험가입자나 피보험자는 보험계약을 체결할 때 보험사에 고지사항을 부실하게 알려서는 안 된다는 의무가 있습니다. 이를 위반할 경우 보험사는 일정 요건 아래 계약을 해지할 수 있지만, 보험사가 해당 사실을 알고 있거나 중대한 과실로 인해 알지 못했을 경우에는 계약을 해지할 수 없습니다. 또한, 일정 기간이 경과한 경우에도 계약을 해지할 수 없다고 합니다. 따라서 골절과 관련된 보험을 가입하실 때에는 약관에 명시된 의무를 준수해야 합니다. 추가적인 질문이 있으시면 언제든지 물어봐주세요.\n"
     ]
    }
   ],
   "source": [
    "symptom_query = \"골절 관련된 보험에 대해 알려줘\"  # 간단한 주요 키워드로 검색\n",
    "search_insurance_terms(symptom_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변: 네, 교통사고에 대한 다양한 보험 상품이 있습니다. 교통사고처리지원금Ⅲ부터 교통사고처리지원금통합형까지 다양한 옵션이 제공되고 있어요. 이 중에서 영업용운전자 중상해제외로 되어 있는 상품들이 있습니다. 이러한 상품들은 교통사고로 인한 다양한 비용을 보상받을 수 있도록 도와주는데요. 교통사고로 인한 상황에 대비하여 적절한 보험을 가입해두는 것이 중요하니, 자세한 내용은 약관을 참고하시거나 보험상담사와 상담하여 보다 적합한 상품을 선택하시는 것이 좋을 것 같아요.\n"
     ]
    }
   ],
   "source": [
    "symptom_query = \"교통사고에 대한 보험을 다양하게 알려줄수있을까\"  # 간단한 주요 키워드로 검색\n",
    "search_insurance_terms(symptom_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS 인덱스가 './data/new_faiss_index'에 저장되었습니다.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The de-serialization relies loading a pickle file. Pickle files can be modified to deliver a malicious payload that results in execution of arbitrary code on your machine.You will need to set `allow_dangerous_deserialization` to `True` to enable deserialization. If you do this, make sure that you trust the source of the data. For example, if you are loading a file that you created, and know that no one else has modified the file, then this is safe to do. Do not set this to `True` if you are loading a file from an untrusted source (e.g., some random site on the internet.).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFAISS 인덱스가 \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex_folder_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m에 저장되었습니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# 6. FAISS 인덱스 로드\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m loaded_faiss_db \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_folder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# 7. 검색기 생성\u001b[39;00m\n\u001b[0;32m     48\u001b[0m retriever \u001b[38;5;241m=\u001b[39m loaded_faiss_db\u001b[38;5;241m.\u001b[39mas_retriever(search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3\u001b[39m})  \u001b[38;5;66;03m# 관련 결과 3개만 반환\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\lang-chain-3vk4AX8U-py3.11\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1188\u001b[0m, in \u001b[0;36mFAISS.load_local\u001b[1;34m(cls, folder_path, embeddings, index_name, allow_dangerous_deserialization, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load FAISS index, docstore, and index_to_docstore_id from disk.\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \n\u001b[0;32m   1176\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;124;03m        arbitrary code on your machine.\u001b[39;00m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_dangerous_deserialization:\n\u001b[1;32m-> 1188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe de-serialization relies loading a pickle file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPickle files can be modified to deliver a malicious payload that \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults in execution of arbitrary code on your machine.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1192\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou will need to set `allow_dangerous_deserialization` to `True` to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable deserialization. If you do this, make sure that you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust the source of the data. For example, if you are loading a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile that you created, and know that no one else has modified the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1196\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile, then this is safe to do. Do not set this to `True` if you are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading a file from an untrusted source (e.g., some random site on \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe internet.).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1199\u001b[0m     )\n\u001b[0;32m   1200\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(folder_path)\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;66;03m# load index separately since it is not picklable\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: The de-serialization relies loading a pickle file. Pickle files can be modified to deliver a malicious payload that results in execution of arbitrary code on your machine.You will need to set `allow_dangerous_deserialization` to `True` to enable deserialization. If you do this, make sure that you trust the source of the data. For example, if you are loading a file that you created, and know that no one else has modified the file, then this is safe to do. Do not set this to `True` if you are loading a file from an untrusted source (e.g., some random site on the internet.)."
     ]
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# 1. PDF에서 텍스트 추출\n",
    "pdf_file_path = './data/약관_31043(01)_나에게맞춘생활종합보험2404_20241001.pdf'\n",
    "text = extract_text(pdf_file_path)\n",
    "\n",
    "# 2. 텍스트를 청크화 (문서 분할)\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,  # 청크 크기 설정\n",
    "    chunk_overlap=100  # 약간의 오버랩을 두어 문맥 유지\n",
    ")\n",
    "\n",
    "# 텍스트를 청크화하여 문서 목록 생성\n",
    "split_docs = []\n",
    "chunks = splitter.split_text(text)\n",
    "\n",
    "# 청크화된 텍스트를 Document 객체로 변환\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk_metadata = {\n",
    "        \"source\": \"약관\",  # 소스 정보 설정\n",
    "        \"page\": i + 1  # 페이지 정보 설정\n",
    "    }\n",
    "    document = Document(page_content=chunk, metadata=chunk_metadata)\n",
    "    split_docs.append(document)\n",
    "\n",
    "# 3. 임베딩 생성\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# 4. FAISS 벡터 스토어 생성\n",
    "faiss_db = FAISS.from_documents(split_docs, embedding)\n",
    "\n",
    "# 5. FAISS 인덱스 저장\n",
    "index_folder_path = './data/new_faiss_index'\n",
    "faiss_db.save_local(index_folder_path)\n",
    "print(f\"FAISS 인덱스가 '{index_folder_path}'에 저장되었습니다.\")\n",
    "\n",
    "# 6. FAISS 인덱스 로드\n",
    "loaded_faiss_db = FAISS.load_local(index_folder_path, embedding)\n",
    "\n",
    "# 7. 검색기 생성\n",
    "retriever = loaded_faiss_db.as_retriever(search_kwargs={\"k\": 3})  # 관련 결과 3개만 반환\n",
    "\n",
    "# 8. 증상 기반 검색 함수 정의\n",
    "def search_insurance_terms(symptom):\n",
    "    \"\"\"\n",
    "    주어진 증상(symptom)과 관련된 보험 약관을 검색하고,\n",
    "    가장 관련성 높은 문서를 추출한 뒤, 챗봇 스타일의 응답을 생성하는 함수.\n",
    "    \"\"\"\n",
    "    results = retriever.get_relevant_documents(symptom)  # 증상 기반 검색\n",
    "    if results:\n",
    "        # 첫 번째 결과는 가장 유사도가 높은 문서\n",
    "        best_result = results[0]\n",
    "        \n",
    "        # 결과 요약\n",
    "        summary = best_result.page_content[:500]  # 500자까지 출력\n",
    "        summary = summary.replace('\\n', ' ')  # 줄바꿈 제거\n",
    "\n",
    "        # 챗봇 응답을 위한 자연스러운 대화 생성\n",
    "        prompt_template = \"\"\"\n",
    "        주어진 보험 약관에 대한 정보를 바탕으로 아래와 같이 질문에 대해 답변을 해주세요:\n",
    "        \n",
    "        사용자가 궁금해하는 주제: {symptom}\n",
    "        관련 내용: {summary}\n",
    "        \n",
    "        질문에 대한 자연스럽고 대화식으로 답변을 생성해주세요.\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt = PromptTemplate(input_variables=[\"symptom\", \"summary\"], template=prompt_template)\n",
    "        \n",
    "        llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)  # ChatOpenAI 사용\n",
    "        chain = LLMChain(llm=llm, prompt=prompt)\n",
    "        \n",
    "        # 자연스러운 대화식 답변 생성\n",
    "        response = chain.run({\"symptom\": symptom, \"summary\": summary})\n",
    "\n",
    "        print(f\"답변: {response}\")\n",
    "    else:\n",
    "        print(\"관련된 내용이 없습니다.\")\n",
    "\n",
    "# 9. 테스트: 증상 검색\n",
    "symptom_query = \"아나팔락시스 보험\"  # 간단한 주요 키워드로 검색\n",
    "search_insurance_terms(symptom_query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang-chain-3vk4AX8U-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
